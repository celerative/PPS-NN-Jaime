{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepTesla@Celerative (Udacity simulator dataset) (in English)\n",
    "### Inspiration\n",
    "* http://selfdrivingcars.mit.edu/deeptesla/\n",
    "* https://github.com/naokishibuya/car-behavioral-cloning\n",
    "\n",
    "### Objective\n",
    "* Design and implement a CNN to predict the steering angle from the pictures taken from vehicle cameras.\n",
    "* Use the Udacity Self-Driving Car Simulator to test the CNN.\n",
    "\n",
    "### Resources\n",
    "* Keras documentation: https://keras.io/\n",
    "* OpenCV documentation: http://opencv.org/\n",
    "* Introduction to Udacity Self-Driving Car Simulator: https://medium.com/towards-data-science/introduction-to-udacity-self-driving-car-simulator-4d78198d301d\n",
    "\n",
    "### Useful links\n",
    "* Augmentation based DNN: https://chatbotslife.com/using-augmentation-to-mimic-human-driving-496b569760a9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility definitions and functions (utils.py)\n",
    "\n",
    "The script to provide useful functionalities (i.e. image preprocessing and augumentation)\n",
    "\n",
    "utils.py is originally from https://github.com/naokishibuya/car-behavioral-cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import cv2, os\n",
    "\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 64, 128, 3\n",
    "INPUT_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
    "\n",
    "def load_image(data_dir, image_file):\n",
    "    \"\"\"\n",
    "    Load RGB images from a file\n",
    "    \"\"\"\n",
    "    return mpimg.imread(os.path.join(data_dir, image_file.strip()))\n",
    "\n",
    "def crop(image):\n",
    "    \"\"\"\n",
    "    Crop the image (removing the sky at the top and the car front at the bottom)\n",
    "    \"\"\"\n",
    "    return image[60:-25, :, :] # remove the sky and the car front\n",
    "\n",
    "def resize(image):\n",
    "    \"\"\"\n",
    "    Resize the image to the input shape used by the network model\n",
    "    \"\"\"\n",
    "    return cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), cv2.INTER_AREA)\n",
    "\n",
    "def rgb2yuv(image):\n",
    "    \"\"\"\n",
    "    Convert the image from RGB to YUV (This is what the NVIDIA model does)\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "\n",
    "def preprocess(image):\n",
    "    \"\"\"\n",
    "    Combine all preprocess functions into one\n",
    "    \"\"\"\n",
    "    image = crop(image)\n",
    "    image = resize(image)\n",
    "    image = rgb2yuv(image)\n",
    "    return image\n",
    "\n",
    "def choose_image(data_dir, center, left, right, steering_angle):\n",
    "    \"\"\"\n",
    "    Randomly choose an image from the center, left or right, and adjust\n",
    "    the steering angle.\n",
    "    \"\"\"\n",
    "    choice = np.random.choice(3)\n",
    "    if choice == 0:\n",
    "        return load_image(data_dir, left), steering_angle + 0.2\n",
    "    elif choice == 1:\n",
    "        return load_image(data_dir, right), steering_angle - 0.2\n",
    "    return load_image(data_dir, center), steering_angle\n",
    "\n",
    "def random_flip(image, steering_angle):\n",
    "    \"\"\"\n",
    "    Randomly flipt the image left <-> right, and adjust the steering angle.\n",
    "    \"\"\"\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        steering_angle = -steering_angle\n",
    "    return image, steering_angle\n",
    "\n",
    "def random_translate(image, steering_angle, range_x, range_y):\n",
    "    \"\"\"\n",
    "    Randomly shift the image virtially and horizontally (translation).\n",
    "    \"\"\"\n",
    "    trans_x = range_x * (np.random.rand() - 0.5)\n",
    "    trans_y = range_y * (np.random.rand() - 0.5)\n",
    "    steering_angle += trans_x * 0.002\n",
    "    trans_m = np.float32([[1, 0, trans_x], [0, 1, trans_y]])\n",
    "    height, width = image.shape[:2]\n",
    "    image = cv2.warpAffine(image, trans_m, (width, height))\n",
    "    return image, steering_angle\n",
    "\n",
    "def random_shadow(image):\n",
    "    \"\"\"\n",
    "    Generates and adds random shadow\n",
    "    \"\"\"\n",
    "    # (x1, y1) and (x2, y2) forms a line\n",
    "    # xm, ym gives all the locations of the image\n",
    "    x1, y1 = IMAGE_WIDTH * np.random.rand(), 0\n",
    "    x2, y2 = IMAGE_WIDTH * np.random.rand(), IMAGE_HEIGHT\n",
    "    xm, ym = np.mgrid[0:IMAGE_HEIGHT, 0:IMAGE_WIDTH]\n",
    "\n",
    "    # mathematically speaking, we want to set 1 below the line and zero otherwise\n",
    "    # Our coordinate is up side down.  So, the above the line: \n",
    "    # (ym-y1)/(xm-x1) > (y2-y1)/(x2-x1)\n",
    "    # as x2 == x1 causes zero-division problem, we'll write it in the below form:\n",
    "    # (ym-y1)*(x2-x1) - (y2-y1)*(xm-x1) > 0\n",
    "    mask = np.zeros_like(image[:, :, 1])\n",
    "    mask[(ym - y1) * (x2 - x1) - (y2 - y1) * (xm - x1) > 0] = 1\n",
    "\n",
    "    # choose which side should have shadow and adjust saturation\n",
    "    cond = mask == np.random.randint(2)\n",
    "    s_ratio = np.random.uniform(low=0.2, high=0.5)\n",
    "\n",
    "    # adjust Saturation in HLS(Hue, Light, Saturation)\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    hls[:, :, 1][cond] = hls[:, :, 1][cond] * s_ratio\n",
    "    return cv2.cvtColor(hls, cv2.COLOR_HLS2RGB)\n",
    "\n",
    "def random_brightness(image):\n",
    "    \"\"\"\n",
    "    Randomly adjust brightness of the image.\n",
    "    \"\"\"\n",
    "    # HSV (Hue, Saturation, Value) is also called HSB ('B' for Brightness).\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    ratio = 1.0 + 0.4 * (np.random.rand() - 0.5)\n",
    "    hsv[:,:,2] =  hsv[:,:,2] * ratio\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "def augument(data_dir, center, left, right, steering_angle, range_x=100, range_y=10):\n",
    "    \"\"\"\n",
    "    Generate an augumented image and adjust steering angle.\n",
    "    (The steering angle is associated with the center image)\n",
    "    \"\"\"\n",
    "    image, steering_angle = choose_image(data_dir, center, left, right, steering_angle)\n",
    "    image, steering_angle = random_flip(image, steering_angle)\n",
    "    image, steering_angle = random_translate(image, steering_angle, range_x, range_y)\n",
    "    image = random_shadow(image)\n",
    "    image = random_brightness(image)\n",
    "    return image, steering_angle\n",
    "\n",
    "def batch_generator(data_dir, image_paths, steering_angles, batch_size, is_training):\n",
    "    \"\"\"\n",
    "    Generate training image give image paths and associated steering angles\n",
    "    \"\"\"\n",
    "    images = np.empty([batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS])\n",
    "    steers = np.empty(batch_size)\n",
    "    while True:\n",
    "        i = 0\n",
    "        for index in np.random.permutation(image_paths.shape[0]):\n",
    "            center, left, right = image_paths[index]\n",
    "            steering_angle = steering_angles[index]\n",
    "            # argumentation\n",
    "            if is_training and np.random.rand() < 0.6:\n",
    "                image, steering_angle = augument(data_dir, center, left, right, steering_angle)\n",
    "            else:\n",
    "                image = load_image(data_dir, center) \n",
    "            # add the image and steering angle to the batch\n",
    "            images[i] = preprocess(image)\n",
    "            steers[i] = steering_angle\n",
    "            i += 1\n",
    "            if i == batch_size:\n",
    "                break\n",
    "        yield images, steers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Models\n",
    "\n",
    "Two models were designed and empirically tuned-up.\n",
    "\n",
    "Both models feature a first lambda layer that normalize the input range from [0; 255] to [-1; 1]\n",
    "\n",
    "Also both models will be trained to output a normalized [-1; 1] angle.\n",
    "\n",
    "* Flat model:\n",
    "    \"Flat and dense\" model. Features only few layers compared to the current CNNs commonly used.\n",
    "* Nvidia-style model:\n",
    "    Deep NN model. Based on the models from: \n",
    "    * https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf (Chapter 5 - Fig. 4)\n",
    "    * https://web.wpi.edu/Pubs/E-project/Available/E-project-032317-223611/unrestricted/Reportv4.pdf (Chapter 4 - Fig. 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Lambda, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\"\"\"\n",
    "Flat model\n",
    "\"\"\"\n",
    "def build_flat_model():\n",
    "    model = Sequential() # 64x128 x 3\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1,\n",
    "              input_shape = INPUT_SHAPE))\n",
    "    \n",
    "    model.add(Conv2D(8, (3, 3), padding = 'same',\n",
    "                     activation = 'elu')) # 64x128 x 8\n",
    "\n",
    "    model.add(Conv2D(16, (3, 3), padding = 'same',\n",
    "                     activation = 'elu')) # 64x128 x 16\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2))) # 32x64 x 16\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128, activation = 'elu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    model.compile(loss = 'mean_squared_error',\n",
    "                  optimizer = Adam(lr = 1.0e-4))\n",
    "#                  optimizer = 'adadelta')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "Nvidia-style model\n",
    "\"\"\"\n",
    "def build_nv_model():\n",
    "    model = Sequential() # 64x128x3\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1,\n",
    "              input_shape = INPUT_SHAPE))\n",
    "    \n",
    "    model.add(Conv2D(24, (5, 5), activation = 'elu',\n",
    "                     padding = 'same')) # 64x128 x 24\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2))) # 32x64 x 24\n",
    "\n",
    "    model.add(Conv2D(36, (5, 5), activation = 'elu')) # 28x60 x 36\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2))) # 14x30 x 36\n",
    "\n",
    "    model.add(Conv2D(48, (5, 5), activation = 'elu')) # 10x26 x 48\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2))) # 5x13 x 48\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation = 'elu')) # 3x11 x 64\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation = 'elu')) # 1x9 x 64\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(100, activation = 'elu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(50, activation = 'elu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(10, activation = 'elu'))\n",
    "\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "    model.compile(loss = 'mean_squared_error',\n",
    "                  optimizer = Adam(lr = 1.0e-4))\n",
    "#                  optimizer = 'adadelta')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data generated by the simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(data_dir, test_size = .2):\n",
    "    \"\"\"\n",
    "    Load training data and split it into training and validation set\n",
    "    \"\"\"\n",
    "    data_df = pd.read_csv(os.path.join(data_dir, 'driving_log.csv'), header = None,\n",
    "                          names = ['center', 'left', 'right', 'steering', 'e', 'f', 'speed'],\n",
    "                          dtype = {'center': str,\n",
    "                                   'left': str,\n",
    "                                   'right': str,\n",
    "                                   'steering': np.float32 })\n",
    "    \n",
    "    X = data_df[['center', 'left', 'right']].values\n",
    "    y = data_df['steering'].values\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=0)\n",
    "\n",
    "    return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Training\n",
    "\n",
    "Already trained models can be downloaded from:\n",
    "* Nvidia-style models: https://drive.google.com/file/d/0B8PJB_fXB-_FYS1oOWotQVBpd2c/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jameru/Projects/pps/env/lib/python3.5/site-packages/ipykernel_launcher.py:90: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 0; dimension is 160 but corresponding boolean dimension is 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: saving model to uda-flat-model-200.h5\n",
      "267s - loss: 0.0243 - val_loss: 0.0136\n",
      "Epoch 2/5\n",
      "Epoch 00001: saving model to uda-flat-model-201.h5\n",
      "268s - loss: 0.0230 - val_loss: 0.0157\n",
      "Epoch 3/5\n",
      "Epoch 00002: saving model to uda-flat-model-202.h5\n",
      "265s - loss: 0.0239 - val_loss: 0.0146\n",
      "Epoch 4/5\n",
      "Epoch 00003: saving model to uda-flat-model-203.h5\n",
      "266s - loss: 0.0234 - val_loss: 0.0153\n",
      "Epoch 5/5\n",
      "Epoch 00004: saving model to uda-flat-model-204.h5\n",
      "266s - loss: 0.0217 - val_loss: 0.0146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6e1eade48>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Hyper-parameters\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "data_dir = \"/mnt/j/Datasets/udacity-sim/\"\n",
    "\n",
    "# Data!\n",
    "X_train, X_valid, y_train, y_valid = load_data(data_dir)\n",
    "\n",
    "#model = build_flat_model()\n",
    "model = load_model('uda-flat-model-104.h5')\n",
    "\n",
    "checkpoint = ModelCheckpoint('uda-flat-model-2{epoch:02d}.h5',\n",
    "                             monitor = 'val_loss',\n",
    "                             verbose = 1,\n",
    "#                             save_best_only = True,\n",
    "                             mode = 'auto')\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss',\n",
    "                          min_delta = 0.,\n",
    "                          patience = 4,\n",
    "                          verbose = 0)\n",
    "\n",
    "model.fit_generator(batch_generator(data_dir, X_train, y_train, batch_size, True),\n",
    "                    steps_per_epoch = 500,\n",
    "                    epochs = epochs,\n",
    "                    validation_data = batch_generator(data_dir, X_valid, y_valid, batch_size, False),\n",
    "                    validation_steps = len(X_valid) // batch_size,\n",
    "                    callbacks = [checkpoint],\n",
    "                    verbose = 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "* uda-nv-model-104.h5 takes an alternative route at the first track, then it succesfully returns to the main track.\n",
    "* uda-nv-model-204.h5 already completes the main track.\n",
    "* At uda-nv-model-304.h5, loss and val_loss begin to converge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
