{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepTesla Jr.\n",
    "## ExtracciÃ³n de frames de los videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "base_path = \"J:/Datasets/deeptesla/\"\n",
    "validation_set = [9, 10]\n",
    "frames_writed = 0\n",
    "\n",
    "for video_id in xrange(1, 11):\n",
    "    video_filename = \"epoch%02d_front.mkv\" % video_id\n",
    "    video_path = os.path.join(base_path, video_filename)\n",
    "    assert os.path.isfile(video_path)\n",
    "\n",
    "    # Create capturator\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    print(\"Capturing from \", video_path)\n",
    "\n",
    "    # Capture first frame\n",
    "    ret, frame = cap.read()\n",
    "    assert ret\n",
    "\n",
    "    # Print shape\n",
    "    shape = frame.shape\n",
    "    print(shape)\n",
    "\n",
    "    while (ret):\n",
    "        # Crop frame \n",
    "        img = frame[int(shape[0]/2):shape[0], 0:shape[1]]\n",
    "        # Resize the image\n",
    "        img = cv2.resize(img, (128, 64), interpolation=cv2.INTER_AREA)\n",
    "        # Resize the image sized as a 4D array\n",
    "        img = np.resize(img, (64, 128, 3))\n",
    "        \n",
    "        # Save the image\n",
    "        if video_id in validation_set:\n",
    "            image_path = os.path.join(base_path, \"validation/frame%05d.jpg\" % frames_writed)\n",
    "        else:\n",
    "            image_path = os.path.join(base_path, \"training/frame%05d.jpg\" % frames_writed)\n",
    "        cv2.imwrite(image_path, img)\n",
    "        frames_writed += 1\n",
    "        if frames_writed % 100 == 0:\n",
    "            print(\"Writed %d images...\" % frames_writed)\n",
    "\n",
    "        # Display\n",
    "        #cv2.imshow('frame', frame)\n",
    "        #cv2.imshow('img', img)\n",
    "\n",
    "        # User exit?\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Capture next frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "    # Release the capture\n",
    "    cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de la CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21600 samples, validate on 5400 samples\n",
      "Epoch 1/6\n",
      "14592/21600 [===================>..........] - ETA: 105s - loss: 16.6062"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "#import scipy\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 6\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'deeptesla_trained_model.h5'\n",
    "\n",
    "filelist = glob.glob(\"/mnt/j/Datasets/deeptesla/training/*.jpg\")\n",
    "x_train = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "filelist = glob.glob(\"/mnt/j/Datasets/deeptesla/validation/*.jpg\")\n",
    "x_test = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "\n",
    "y_train = np.genfromtxt(\"/mnt/j/Datasets/deeptesla/training.csv\", delimiter = ',')\n",
    "y_test = np.genfromtxt(\"/mnt/j/Datasets/deeptesla/validation.csv\", delimiter = ',')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, (3, 3), padding = 'same',\n",
    "                 input_shape = x_train[0].shape))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(8, (3, 3),\n",
    "                 kernel_initializer = 'glorot_normal'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(8, (3, 3),\n",
    "                 kernel_initializer = 'glorot_normal'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "model.compile(loss = 'mean_squared_error',\n",
    "              optimizer = 'adadelta')\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs,\n",
    "          validation_data = (x_test, y_test),\n",
    "          shuffle = False,\n",
    "          verbose = 1)\n",
    "\n",
    "# Save model and weights\n",
    "#if not os.path.isdir(save_dir):\n",
    "#    os.makedirs(save_dir)\n",
    "\n",
    "#model_path = os.path.join(save_dir, model_name)\n",
    "#model.save(model_path)\n",
    "\n",
    "#print('Saved trained model at %s ' % model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
