{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepTesla Jr.\n",
    "## Extracci√≥n de frames de los videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "base_path = \"J:/Datasets/deeptesla/\"\n",
    "validation_set = [9, 10]\n",
    "frames_writed = 0\n",
    "\n",
    "for video_id in xrange(1, 11):\n",
    "    video_filename = \"epoch%02d_front.mkv\" % video_id\n",
    "    video_path = os.path.join(base_path, video_filename)\n",
    "    assert os.path.isfile(video_path)\n",
    "\n",
    "    # Create capturator\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    print(\"Capturing from \", video_path)\n",
    "\n",
    "    # Capture first frame\n",
    "    ret, frame = cap.read()\n",
    "    assert ret\n",
    "\n",
    "    # Print shape\n",
    "    shape = frame.shape\n",
    "    print(shape)\n",
    "\n",
    "    while (ret):\n",
    "        # Crop frame \n",
    "        img = frame[int(shape[0]/2):shape[0], 0:shape[1]]\n",
    "        # Resize the image\n",
    "        img = cv2.resize(img, (128, 64), interpolation=cv2.INTER_AREA)\n",
    "        # Resize the image sized as a 4D array\n",
    "        img = np.resize(img, (64, 128, 3))\n",
    "        \n",
    "        # Save the image\n",
    "        if video_id in validation_set:\n",
    "            image_path = os.path.join(base_path, \"validation/frame%05d.jpg\" % frames_writed)\n",
    "        else:\n",
    "            image_path = os.path.join(base_path, \"training/frame%05d.jpg\" % frames_writed)\n",
    "        cv2.imwrite(image_path, img)\n",
    "        frames_writed += 1\n",
    "        if frames_writed % 100 == 0:\n",
    "            print(\"Writed %d images...\" % frames_writed)\n",
    "\n",
    "        # Display\n",
    "        #cv2.imshow('frame', frame)\n",
    "        #cv2.imshow('img', img)\n",
    "\n",
    "        # User exit?\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Capture next frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "    # Release the capture\n",
    "    cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Una primera mirada a los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdd48ae98d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAETxJREFUeJzt3X+MpVddx/H3x0LRILL9sW42u6tTZYVUE0qdYIlIKhXt\nD+MWAw1o6NqsWUiK0aDRxX9Qo8liohX8UbNaZGv4VdCmG9ogdQGJiS1MaS20pem0brO72XZHKPVH\nFS18/eOelbvL7s69M3f2zhzer+Tmnuc857n3nLm5nzlz7nOfSVUhSerXt027A5KklWXQS1LnDHpJ\n6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjr3nGl3AOD888+vmZmZaXdDktaUe+6551+rav1i\n7VZF0M/MzDA3NzftbkjSmpLk8VHauXQjSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnFg36\nJC9Oct/Q7d+S/EqSc5PcmeSRdn9Oa58k704yn+T+JBev/DAkSaeyaNBX1cNVdVFVXQT8MPAMcCuw\nC9hfVVuB/W0b4Apga7vtBG5ciY5LkkYz7jdjLwMerarHk2wDLm31e4FPAb8BbANursF/Hb8rybok\nG6vqyIT6LI1kZtftx20f2H3VlHoiTde4a/RvAD7QyhuGwvsJYEMrbwIODh1zqNVJkqZg5KBPcjbw\nM8CHT9zXZu81zhMn2ZlkLsncwsLCOIdKksYwzoz+CuBzVfVk234yyUaAdn+01R8Gtgwdt7nVHaeq\n9lTVbFXNrl+/6MXXJElLNE7Qv5FvLNsA7AO2t/J24Lah+mvb2TeXAE+7Pi9J0zPSh7FJng+8Bnjz\nUPVu4JYkO4DHgWta/R3AlcA8gzN0rptYbyVJYxsp6KvqP4HzTqj7EoOzcE5sW8D1E+mdJGnZ/Gas\nJHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS\n5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6N1LQJ1mX5CNJvpjkoSSvSHJukjuTPNLu\nz2ltk+TdSeaT3J/k4pUdgiTpdEad0b8L+FhVvQR4KfAQsAvYX1Vbgf1tG+AKYGu77QRunGiPJUlj\nWTTok7wQeBVwE0BV/U9VfQXYBuxtzfYCV7fyNuDmGrgLWJdk48R7LkkaySgz+guABeCvktyb5C+T\nPB/YUFVHWpsngA2tvAk4OHT8oVYnSZqCUYL+OcDFwI1V9TLgP/nGMg0AVVVAjfPESXYmmUsyt7Cw\nMM6hkqQxPGeENoeAQ1V1d9v+CIOgfzLJxqo60pZmjrb9h4EtQ8dvbnXHqao9wB6A2dnZsX5JSCtt\nZtft31R3YPdVU+iJtHyLzuir6gngYJIXt6rLgAeBfcD2VrcduK2V9wHXtrNvLgGeHlrikSSdYaPM\n6AF+CXhfkrOBx4DrGPySuCXJDuBx4JrW9g7gSmAeeKa1lSRNyUhBX1X3AbMn2XXZSdoWcP0y+yVJ\nmhC/GStJnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJek\nzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUuZGCPsmBJJ9Pcl+SuVZ3\nbpI7kzzS7s9p9Uny7iTzSe5PcvFKDkCSdHrjzOh/vKouqqrZtr0L2F9VW4H9bRvgCmBru+0EbpxU\nZyVJ41vO0s02YG8r7wWuHqq/uQbuAtYl2biM55EkLcOoQV/Ax5Pck2Rnq9tQVUda+QlgQytvAg4O\nHXuo1R0nyc4kc0nmFhYWltB1SdIonjNiu1dW1eEk3w3cmeSLwzurqpLUOE9cVXuAPQCzs7NjHStJ\nGt1IM/qqOtzujwK3Ai8Hnjy2JNPuj7bmh4EtQ4dvbnWSpClYNOiTPD/JC46VgZ8EvgDsA7a3ZtuB\n21p5H3BtO/vmEuDpoSUeSdIZNsrSzQbg1iTH2r+/qj6W5LPALUl2AI8D17T2dwBXAvPAM8B1E++1\nJGlkiwZ9VT0GvPQk9V8CLjtJfQHXT6R3kqRl85uxktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMG\nvSR1zqCXpM4Z9JLUOYNekjo36mWKpRU1s+v247YP7L7qjB4v9cwZvSR1zqCXpM4Z9JLUOYNekjpn\n0EtS5wx6Seqcp1dKY/A0Tq1FzuglqXMGvSR1buSgT3JWknuTfLRtX5Dk7iTzST6U5OxW/7y2Pd/2\nz6xM1yVJoxhnRv/LwEND2+8EbqiqFwFPATta/Q7gqVZ/Q2snSZqSkT6MTbIZuAr4PeBtSQK8Gvi5\n1mQv8FvAjcC2Vgb4CPAnSVJVNblu61uBH3xKkzHqjP6PgF8Hvt62zwO+UlXPtu1DwKZW3gQcBGj7\nn27tJUlTsGjQJ/lp4GhV3TPJJ06yM8lckrmFhYVJPrQkacgoM/ofBX4myQHggwyWbN4FrEtybOln\nM3C4lQ8DWwDa/hcCXzrxQatqT1XNVtXs+vXrlzUISdKpLbpGX1VvB94OkORS4Neq6ueTfBh4HYPw\n3w7c1g7Z17b/qe3/hOvzWi1c99e3ouWcR/8bDD6YnWewBn9Tq78JOK/Vvw3YtbwuSpKWY6xLIFTV\np4BPtfJjwMtP0ua/gddPoG+SpAnwm7GS1DkvaqY1Z9Lr7K7bq3fO6CWpcwa9JHXOoJekzhn0ktQ5\ng16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM55rRtpmbxWjlY7Z/SS1DmDXpI6Z9BLUucM\neknqnEEvSZ0z6CWpc4sGfZJvT/KZJP+c5IEkv93qL0hyd5L5JB9Kcnarf17bnm/7Z1Z2CJKk0xll\nRv9V4NVV9VLgIuDyJJcA7wRuqKoXAU8BO1r7HcBTrf6G1k6SNCWLBn0N/EfbfG67FfBq4COtfi9w\ndStva9u0/ZclycR6LEkay0hr9EnOSnIfcBS4E3gU+EpVPduaHAI2tfIm4CBA2/80cN4kOy1JGt1I\nQV9VX6uqi4DNwMuBlyz3iZPsTDKXZG5hYWG5DydJOoWxzrqpqq8AnwReAaxLcuxaOZuBw618GNgC\n0Pa/EPjSSR5rT1XNVtXs+vXrl9h9SdJiRjnrZn2Sda38HcBrgIcYBP7rWrPtwG2tvK9t0/Z/oqpq\nkp2WJI1ulKtXbgT2JjmLwS+GW6rqo0keBD6Y5HeBe4GbWvubgL9OMg98GXjDCvRbkjSiRYO+qu4H\nXnaS+scYrNefWP/fwOsn0jtJ0rL5zVhJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUuVHOo5c0ATO7\nbj9u+8Duq6bUE32rcUYvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+gl\nqXMGvSR1zqCXpM4Z9JLUOYNekjq3aNAn2ZLkk0keTPJAkl9u9ecmuTPJI+3+nFafJO9OMp/k/iQX\nr/QgJEmnNsqM/lngV6vqQuAS4PokFwK7gP1VtRXY37YBrgC2tttO4MaJ91qSNLJFg76qjlTV51r5\n34GHgE3ANmBva7YXuLqVtwE318BdwLokGyfec0nSSMZao08yA7wMuBvYUFVH2q4ngA2tvAk4OHTY\noVZ34mPtTDKXZG5hYWHMbkuSRjXyvxJM8p3A3wC/UlX/luT/91VVJalxnriq9gB7AGZnZ8c6Vlrt\n/LeBWk1GmtEneS6DkH9fVf1tq37y2JJMuz/a6g8DW4YO39zqJElTMMpZNwFuAh6qqj8c2rUP2N7K\n24HbhuqvbWffXAI8PbTEI0k6w0ZZuvlR4E3A55Pc1+p+E9gN3JJkB/A4cE3bdwdwJTAPPANcN9Ee\nS5LGsmjQV9U/AjnF7stO0r6A65fZL0nShPjNWEnqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16S\nOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SercKP9KUNIKmdl1\n+3HbB3ZfNaWeqGfO6CWpcwa9JHVu0aWbJO8Bfho4WlU/1OrOBT4EzAAHgGuq6qkkAd4FXAk8A/xC\nVX1uZbqutcrlitM78ecD/oy0PKPM6N8LXH5C3S5gf1VtBfa3bYArgK3tthO4cTLdlCQt1aJBX1Wf\nBr58QvU2YG8r7wWuHqq/uQbuAtYl2TipzkqSxrfUNfoNVXWklZ8ANrTyJuDgULtDrU6SNCXL/jC2\nqgqocY9LsjPJXJK5hYWF5XZDknQKSw36J48tybT7o63+MLBlqN3mVvdNqmpPVc1W1ez69euX2A1J\n0mKWGvT7gO2tvB24baj+2gxcAjw9tMQjSZqCUU6v/ABwKXB+kkPAO4DdwC1JdgCPA9e05ncwOLVy\nnsHpldetQJ8lSWNYNOir6o2n2HXZSdoWcP1yOyVJmhy/GStJnTPoJalzBr0kdc6gl6TOGfSS1DmD\nXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnFr0evaTVYWbX7cdt\nH9h91ZR6orXGGb0kdc6gl6TOGfSS1DnX6HVay10Xdl1Zmr4VmdEnuTzJw0nmk+xaieeQJI1m4jP6\nJGcBfwq8BjgEfDbJvqp6cNLPpek4cZYOg5m6s/czz5+5RrESM/qXA/NV9VhV/Q/wQWDbCjyPJGkE\nKxH0m4CDQ9uHWp0kaQpSVZN9wOR1wOVV9Ytt+03Aj1TVW09otxPY2TZfDDy8xKc8H/jXJR67GvU0\nnp7GAo5ntetpPKOO5Xurav1ijVbirJvDwJah7c2t7jhVtQfYs9wnSzJXVbPLfZzVoqfx9DQWcDyr\nXU/jmfRYVmLp5rPA1iQXJDkbeAOwbwWeR5I0gonP6Kvq2SRvBf4OOAt4T1U9MOnnkSSNZkW+MFVV\ndwB3rMRjn8Syl39WmZ7G09NYwPGsdj2NZ6JjmfiHsZKk1cVr3UhS59Zk0Cd5fZIHknw9yexQ/UyS\n/0pyX7v9+TT7OapTjafte3u7lMTDSX5qWn1cqiS/leTw0Gty5bT7tBQ9XdYjyYEkn2+vx9y0+zOu\nJO9JcjTJF4bqzk1yZ5JH2v050+zjOE4xnom+b9Zk0ANfAH4W+PRJ9j1aVRe121vOcL+W6qTjSXIh\ng7OWfhC4HPizdomJteaGodfkTH12MzFDl/W4ArgQeGN7bdayH2+vx1o8HfG9DN4Pw3YB+6tqK7C/\nba8V7+WbxwMTfN+syaCvqoeqaqlfsFp1TjOebcAHq+qrVfUvwDyDS0zozPKyHqtIVX0a+PIJ1duA\nva28F7j6jHZqGU4xnolak0G/iAuS3JvkH5L82LQ7s0y9XE7irUnub3+irpk/qYf08jocU8DHk9zT\nvqHegw1VdaSVnwA2TLMzEzKx982qDfokf5/kCye5nW4mdQT4nqp6GfA24P1JvuvM9Pj0ljieNWGR\nsd0IfD9wEYPX5w+m2lkBvLKqLmawFHV9kldNu0OTVINTCdf66YQTfd+s2n88UlU/sYRjvgp8tZXv\nSfIo8APA1D9wWsp4GPFyEtM26tiS/AXw0RXuzkpYE6/DqKrqcLs/muRWBktTJ/u8ay15MsnGqjqS\nZCNwdNodWo6qevJYeRLvm1U7o1+KJOuPfViZ5PuArcBj0+3VsuwD3pDkeUkuYDCez0y5T2Npb7pj\nXsvgg+e1ppvLeiR5fpIXHCsDP8nafE1OtA/Y3srbgdum2Jdlm/T7ZtXO6E8nyWuBPwbWA7cnua+q\nfgp4FfA7Sf4X+Drwlqpa0Q85JuFU46mqB5LcAjwIPAtcX1Vfm2Zfl+D3k1zE4E/pA8Cbp9ud8XV2\nWY8NwK1JYPD+f39VfWy6XRpPkg8AlwLnJzkEvAPYDdySZAfwOHDN9Ho4nlOM59JJvm/8Zqwkda6r\npRtJ0jcz6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6tz/AZKG4tI9or8PAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdd42f22e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "step = 0.5\n",
    "\n",
    "y_train = np.genfromtxt(\"/mnt/j/Datasets/deeptesla/training.csv\", delimiter = ',')\n",
    "y_test = np.genfromtxt(\"/mnt/j/Datasets/deeptesla/validation.csv\", delimiter = ',')\n",
    "\n",
    "y_train_hist, bins = np.histogram(y_train, bins = np.arange(-15, 15, step))\n",
    "y_test_hist, bins = np.histogram(y_test, bins = bins)\n",
    "\n",
    "width = 0.8 * step\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, y_train_hist, align='center', width=width)\n",
    "plt.show()\n",
    "plt.bar(center, y_test_hist, align='center', width=width)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de la CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21600, 64, 128, 3)\n",
      "(64, 128, 3)\n",
      "(21600,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 128, 8)        224       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 128, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 62, 126, 8)        584       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 62, 126, 8)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 63, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 31, 63, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 15624)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               8000000   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,001,321\n",
      "Trainable params: 8,001,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 21600 samples, validate on 5400 samples\n",
      "Epoch 1/6\n",
      "21600/21600 [==============================] - 513s - loss: 5.6256 - val_loss: 11.8737\n",
      "Epoch 2/6\n",
      "21600/21600 [==============================] - 492s - loss: 4.3115 - val_loss: 6.5664\n",
      "Epoch 3/6\n",
      "21600/21600 [==============================] - 491s - loss: 4.0034 - val_loss: 5.3165\n",
      "Epoch 4/6\n",
      "13760/21600 [==================>...........] - ETA: 168s - loss: 3.6648"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ac47e4261f17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m           \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m           \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m           verbose = 1)\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# Save model and weights#if not os.path.isdir(save_dir):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/pps/env/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/Projects/pps/env/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1593\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m~/Projects/pps/env/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/pps/env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2268\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2269\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2270\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2271\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/pps/env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/pps/env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/pps/env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/Projects/pps/env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/pps/env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "#import scipy\n",
    "\n",
    "epochs = 6\n",
    "\n",
    "batch_size = 32\n",
    "print(\"batch_size = %d\" % batch_size)\n",
    "#save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "#model_name = 'deeptesla_trained_model.h5'\n",
    "\n",
    "x_train = []\n",
    "x_test = []\n",
    "\n",
    "filelist = glob.glob(\"/mnt/j/Datasets/deeptesla/training/*.jpg\")\n",
    "for fname in filelist:\n",
    "    x_train.append(np.array(Image.open(fname)))\n",
    "x_train = np.array(x_train)\n",
    "print(x_train.shape)\n",
    "print(x_train[0].shape)\n",
    "\n",
    "filelist = glob.glob(\"/mnt/j/Datasets/deeptesla/validation/*.jpg\")\n",
    "for fname in filelist:\n",
    "     x_test.append(np.array(Image.open(fname)))\n",
    "x_test = np.array(x_test)\n",
    "        \n",
    "y_train = np.genfromtxt(\"/mnt/j/Datasets/deeptesla/training.csv\", delimiter = ',')\n",
    "y_test = np.genfromtxt(\"/mnt/j/Datasets/deeptesla/validation.csv\", delimiter = ',')\n",
    "print(y_train.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, (3, 3), padding = 'same',\n",
    "                 input_shape = x_train[0].shape))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(8, (3, 3),\n",
    "                 kernel_initializer = 'glorot_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "model.compile(loss = 'mean_squared_error',\n",
    "              optimizer = 'adadelta')\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs,\n",
    "          validation_data = (x_test, y_test),\n",
    "          shuffle = False,\n",
    "          verbose = 1)\n",
    "\n",
    "# Save model and weights#if not os.path.isdir(save_dir):\n",
    "#    os.makedirs(save_dir)\n",
    "\n",
    "#model_path = os.path.join(save_dir, model_name)\n",
    "#model.save(model_path)\n",
    "\n",
    "#print('Saved trained model at %s ' % model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
